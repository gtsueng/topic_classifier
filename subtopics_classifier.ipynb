{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Classifier (specific sub/child categories)\n",
    "This notebooks demonstrates the usage of the scripts supporting classification of outbreak publications, Clinical Trials, and Datasets into specific subcategories or child categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Update all topics\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from src.common import *\n",
    "\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "CLINDATAPATH = os.path.join(SUBDATAPATH ,'ct_topics/')\n",
    "\n",
    "print('fetching litcovid topics')\n",
    "from src.fetch_litcovid_topics import *\n",
    "get_litcovid_topics(DATAPATH)\n",
    "\n",
    "print('updating other broad topics in litcovid')\n",
    "from src.fetch_offtopics import *\n",
    "get_other_topics(DATAPATH,RESULTSPATH)\n",
    "\n",
    "print('updating clinical trials annotations')\n",
    "from src.fetch_clinical_trials import *\n",
    "update_clin_cats(DATAPATH,CLINDATAPATH)\n",
    "\n",
    "print('fetching subtopics from litcovid via keyword-mapping')      \n",
    "from src.fetch_litsubtopics import *\n",
    "from src.fetch_litcovid_topics import *\n",
    "get_sub_topics(DATAPATH,RESULTSPATH)\n",
    "map_keywords(DATAPATH)\n",
    "\n",
    "print('fetching all available subtopic data')\n",
    "from src.fetch_subtopics import *\n",
    "subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "\n",
    "### run time:1h 10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which models need to be updated? (b: broad topics, c: child/sub-topics, a: all topics, s: single topicc\n",
      "Wall time: 1h 41min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## update models\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.train_classifier import *\n",
    "from src.fetch_subtopics import *\n",
    "from src.common import topic_dict\n",
    "\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "SUBMODELPATH = os.path.join(MODELPATH,'subtopics/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "\n",
    "models_to_update = 'i'\n",
    "while models_to_update not in ['b','a','s','c']:\n",
    "    models_to_update = input(\"Which models need to be updated? (b: broad topics, c: child/sub-topics, a: all topics, s: single topic\")\n",
    "\n",
    "if models_to_update == 'a':\n",
    "    topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "    topicsdf.dropna(axis=0,inplace=True)\n",
    "    topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "    generate_models(MODELPATH,topicsdf,classifiers) \n",
    "    subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "    generate_models(SUBMODELPATH,subtopics_only,classifiers,\"all\",False)\n",
    "elif models_to_update == 'b':\n",
    "    topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "    topicsdf.dropna(axis=0,inplace=True)\n",
    "    topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "    generate_models(MODELPATH,topicsdf,classifiers)\n",
    "elif models_to_update == 'c':\n",
    "    subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "    subtopics_only.dropna(axis=0,inplace=True)\n",
    "    generate_models(SUBMODELPATH,subtopics_only,classifiers,\"all\",False)\n",
    "elif models_to_update == 's':\n",
    "    topic_to_check = input(\"enter the topic Category: \")\n",
    "    if topic_to_check in topic_dict['broadtopics']:\n",
    "        topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "        topicsdf.dropna(axis=0,inplace=True)\n",
    "        topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "        generate_models(MODELPATH,topicsdf,classifiers,topic_to_check)\n",
    "    else:\n",
    "        subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "        subtopics_only.dropna(axis=0,inplace=True)\n",
    "        generate_models(SUBMODELPATH,subtopics_only,classifiers,topic_to_check,False)        \n",
    "\n",
    "#### Subtopics update run time: 2hrs 52 min, 2nd run: 1 hr, 41 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### classify publications\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "\n",
    "\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "subtopicsfile = os.path.join(DATAPATH,'subtopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopicsdf = read_csv(subtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "topiclist = topicsdf['topicCategory'].unique().tolist() \n",
    "allsubslist = subtopicsdf['topicCategory'].unique().tolist()\n",
    "subtopiclist = [x for x in allsubslist if x not in topiclist]\n",
    "\n",
    "new_pubs_only,new_topic_ids = check_for_new(RESULTSPATH,topicsdf,\"nonlitcovid\")\n",
    "all_new_ids = list(set(new_pubs_only).union(set(new_topic_ids)))\n",
    "newonly = False\n",
    "alldf = batch_fetch_meta(all_new_ids)\n",
    "alldata = merge_texts(alldf)    \n",
    "\n",
    "classifiers = load_classifiers(\"best\")\n",
    "classifierlist = classifiers.keys()\n",
    "PUBPREDICTPATH = os.path.join(PREDICTPATH,'pubpredict/')\n",
    "SUBMODELPATH = os.path.join(MODELPATH,'subtopics/')\n",
    "\n",
    "if newonly == True:\n",
    "    predict_class(MODELPATH,PUBPREDICTPATH,topiclist,classifierlist,alldata,True)\n",
    "    predict_class(MODELPATH,PUBPREDICTPATH,topiclist,classifierlist,alldata,True)\n",
    "else:\n",
    "    predict_class(SUBMODELPATH,PUBPREDICTPATH,subtopiclist,classifierlist,alldata,False)\n",
    "    predict_class(MODELPATH,PUBPREDICTPATH,topiclist,classifierlist,alldata,False)\n",
    "\n",
    "\n",
    "#### runtime: 1 hr 28 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run tests\n",
    "RESULTPATH = 'results/'\n",
    "testresultsdf = run_test(RESULTPATH,topicsdf,classifierset_type='best',export_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### load annotations for trouble-shooting issues\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "from datetime import datetime\n",
    "\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "#subtopicsfile = os.path.join(DATAPATH,'subtopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "#subtopicsdf = read_csv(subtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopic_results = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf,subtopic_results),ignore_index=True)\n",
    "topicsdf.drop_duplicates(keep='first',inplace=True)\n",
    "topicsdf.reset_index(drop=True)\n",
    "\n",
    "topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "classifiers = load_classifiers('best')\n",
    "newonly=False\n",
    "\n",
    "#classify_clins(DATAPATH,MODELPATH,PREDICTPATH,classifiers,topic_dict)\n",
    "from src.common import topic_dict\n",
    "classifierlist = classifiers.keys()\n",
    "CLINPREDICTPATH = os.path.join(PREDICTPATH,'clinpredict/')\n",
    "PUBPREDICTPATH = os.path.join(PREDICTPATH,'pubpredict/')\n",
    "classify_clins(DATAPATH,MODELPATH,PREDICTPATH,classifiers,topic_dict)\n",
    "clin_total_agree = merge_predictions(CLINPREDICTPATH,topic_dict,classifierlist,agreetype='perfect')\n",
    "if newonly==True:\n",
    "    new_pubs_only,new_topic_ids = check_for_new(RESULTSPATH,topicsdf,\"nonlitcovid\")\n",
    "    all_new_ids = list(set(new_pubs_only).union(set(new_topic_ids)))\n",
    "    classify_pubs(MODELPATH,PUBPREDICTPATH,new_pubs_only,topic_dict,classifiers)\n",
    "    total_agree = merge_predictions(PUBPREDICTPATH,topic_dict,classifierlist,'perfect')\n",
    "    new_total_agree = total_agree.loc[total_agree['_id'].isin(new_pubs_only)].copy()\n",
    "    new_topics_df = topicsdf.loc[topicsdf['_id'].isin(new_topic_ids)].copy()\n",
    "    totalnewresults = pd.concat((new_total_agree,new_topics_df,clin_total_agree),ignore_index=True)\n",
    "    allnewresults = include_clin(totalnewresults)\n",
    "    allnewresults['topicCategory'] = allnewresults['topicCategory'].str.replace('-','/')\n",
    "    allnewresults.dropna(axis=0,inplace=True)\n",
    "    allnewresults.reset_index(drop=True)\n",
    "    cleanresults = clean_results(allnewresults)\n",
    "    cleanresults.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),mode='a',sep='\\t',header=True)\n",
    "else:\n",
    "    all_ids = get_pub_ids(sourceset=\"nonlitcovid\")\n",
    "    classify_pubs(MODELPATH,PUBPREDICTPATH,all_ids,topic_dict,classifiers,False)\n",
    "    total_agree = merge_predictions(PUBPREDICTPATH,topic_dict,classifierlist,'perfect')\n",
    "    totalresults = pd.concat((total_agree,topicsdf,clin_total_agree),ignore_index=True)\n",
    "    print('total results: ',len(totalresults))\n",
    "    allresults = include_clin(totalresults)\n",
    "    print('allresults: ',len(allresults))\n",
    "    allresults['topicCategory'] = allresults['topicCategory'].str.replace('-','/')\n",
    "    allresults.dropna(axis=0,inplace=True)\n",
    "    print('allresults less na: ',len(allresults))\n",
    "    allresults.reset_index(drop=True)\n",
    "    print('allresults with new index: ',len(allresults))\n",
    "    cleanresults = clean_results(allresults) \n",
    "    print('clean results: ',len(cleanresults))\n",
    "    cleanresults.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),mode='w',sep='\\t',header=True)\n",
    "updated_results = read_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "updated_results.drop_duplicates(subset='_id',keep='first',inplace=True)\n",
    "updated_results.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),sep='\\t',header=True)\n",
    "updated_results.to_json(os.path.join(RESULTSPATH,'topicCats.json'), orient='records')\n",
    "\n",
    "####time: 3hrs 14 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\COVID19\\topic_classifier\\src\\fetch_clinical_trials.py\u001b[0m in \u001b[0;36mupdate_clin_cats\u001b[1;34m(DATAPATH, CLINDATAPATH)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[0mclin_meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_fetch_clin_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[0mclin_meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclin_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[0mdump_drug_cats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLINDATAPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclin_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m     \u001b[0mmap_interventions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLINDATAPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclin_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[0mmap_designpurpose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLINDATAPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclin_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\COVID19\\topic_classifier\\src\\fetch_clinical_trials.py\u001b[0m in \u001b[0;36mdump_drug_cats\u001b[1;34m(CLINDATAPATH, clin_meta)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump_drug_cats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLINDATAPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclin_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[0mdrugs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepurpose_cts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_repurpose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclin_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     drug_repurposing = clin_meta.loc[(clin_meta['interventionCategory']=='dietary supplement')|\n\u001b[0;32m    176\u001b[0m                                      (clin_meta['_id'].isin(repurpose_cts))]\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\COVID19\\topic_classifier\\src\\fetch_clinical_trials.py\u001b[0m in \u001b[0;36mget_repurpose\u001b[1;34m(clin_meta)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mdrugfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrug_word_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdrug_word_freq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'counts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mdruglist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrugfreq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'interventionName'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mrepurposedf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_wd_drugs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[0mall_drugs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepurposedf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepurposedf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alias'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mdruglist_lower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdruglist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\COVID19\\topic_classifier\\src\\fetch_clinical_trials.py\u001b[0m in \u001b[0;36mget_wd_drugs\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquerystart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meachwdid\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mqueryend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'format'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'query'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mtmpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_wikidata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mrepurpose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepurpose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmpdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\simplejson\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mparse_constant\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mobject_pairs_hook\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             and not use_decimal and not kw):\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\simplejson\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_PY3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\simplejson\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mord0\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0xef\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'\\xef\\xbb\\xbf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m                 \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## refresh annotations\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "## For refreshing the litcovid annotations\n",
    "from src.fetch_litcovid_topics import *\n",
    "from src.fetch_offtopics import *\n",
    "from src.common import topic_dict\n",
    "from src.fetch_clinical_trials import *\n",
    "from src.fetch_litsubtopics import *\n",
    "from src.fetch_subtopics import *\n",
    "\n",
    "## For refreshing the classification of other resources\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "\n",
    "\n",
    "#### MAIN\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "CLINDATAPATH = os.path.join(SUBDATAPATH,'ct_topics/')\n",
    "\n",
    "#### Refresh the litcovid and Clinical Trials annotations\n",
    "get_litcovid_topics(DATAPATH)\n",
    "get_other_topics(DATAPATH,RESULTSPATH)\n",
    "update_clin_cats(DATAPATH,CLINDATAPATH)\n",
    "get_sub_topics(DATAPATH,RESULTSPATH)\n",
    "map_keywords(DATAPATH)\n",
    "subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "\n",
    "\n",
    "#### Refresh the classification of other resources\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopic_results = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf,subtopic_results),ignore_index=True)\n",
    "topicsdf.drop_duplicates(keep='first',inplace=True)\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "load_annotations(DATAPATH,MODELPATH,PREDICTPATH,RESULTSPATH,topicsdf,classifiers,False)\n",
    "\n",
    "\n",
    "#### run time: 8 hr 46 min\n",
    "#### After efficiency changes implemented, run time was: 2 hr 13 min\n",
    "#### Run time including update of litcovid categories: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inspect the results\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopicsdf = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "subtopicsdf.dropna(axis=0,inplace=True)\n",
    "\n",
    "litsub = subtopicsdf.loc[subtopicsdf['_id'].str.contains('pmid')]\n",
    "litcovidtopics = pd.concat((littopicsdf,offtopicsdf,litsub),ignore_index=True)\n",
    "litcovidtopics.drop_duplicates(keep='first',inplace=True)\n",
    "litcovidtopics.dropna(axis=0,inplace=True)\n",
    "littopicfreq = litcovidtopics.groupby('topicCategory').size().reset_index(name='litcounts')\n",
    "\n",
    "updated_results = read_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),delimiter='\\t',header=0,index_col=0,converters={\"topicCategory\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "check_it = updated_results.explode('topicCategory')\n",
    "frequency = check_it.groupby('topicCategory').size().reset_index(name='allcounts')\n",
    "\n",
    "from src.fetch_subtopics import load_citsci_data\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "curate_df = load_citsci_data(SUBDATAPATH)\n",
    "curate_freq = curate_df.groupby('topicCategory').size().reset_index(name='citsci_counts')\n",
    "curate_freq['topicCategory'] = curate_freq['topicCategory'].str.replace(' / ','/')\n",
    "\n",
    "rawclinical = check_it.loc[check_it['_id'].str.contains('NCT|DKRS|DRKS|ACTRN|ChiCTR|IRCT')].copy()\n",
    "clinicalfreq = clinical.groupby('topicCategory').size().reset_index(name='clinical_counts')\n",
    "\n",
    "rawpreprint = check_it.loc[~(check_it['_id'].str.contains('NCT|DKRS|DRKS|ACTRN|ChiCTR|IRCT|pmid|zenodo|pdb|figshare'))].copy()\n",
    "preprintfreq = rawpreprint.groupby('topicCategory').size().reset_index(name='preprint_count')\n",
    "\n",
    "basic_info = frequency.merge(littopicfreq.merge(curate_freq,on='topicCategory',how='outer'),on='topicCategory',how='outer').fillna(0)\n",
    "freq_info = basic_info.merge(clinicalfreq.merge(preprintfreq,on='topicCategory',how='outer'),on='topicCategory',how='outer').fillna(0)\n",
    "\n",
    "freq_info.to_csv(os.path.join(RESULTSPATH,'topic_frequencies.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
