{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Classifier (specific sub/child categories)\n",
    "This notebooks demonstrates the usage of the scripts supporting classification of outbreak publications, Clinical Trials, and Datasets into specific subcategories or child categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Update training data for clinical trials\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "#### MAIN\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "CLINDATAPATH = os.path.join(SUBDATAPATH,'ct_topics/')\n",
    "\n",
    "\n",
    "from src.fetch_clinical_trials import *\n",
    "update_clin_cats(DATAPATH,CLINDATAPATH)\n",
    "\n",
    "#### time: 1 min, 54 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Update training data for all subtopics\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "#### MAIN\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "CLINDATAPATH = os.path.join(SUBDATAPATH,'ct_topics/')\n",
    "\n",
    "\n",
    "from src.fetch_clinical_trials import *\n",
    "update_clin_cats(DATAPATH,CLINDATAPATH)\n",
    "\n",
    "from src.fetch_litsubtopics import *\n",
    "from src.fetch_litcovid_topics import *\n",
    "get_sub_topics(DATAPATH,RESULTSPATH)\n",
    "map_keywords(DATAPATH)\n",
    "\n",
    "from src.fetch_subtopics import *\n",
    "from src.common import topic_dict\n",
    "subtopics_only = load_subtopics_data(SUBDATAPATH,RESULTSPATH,topic_dict)\n",
    "\n",
    "## This took 1 hr, 40 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching litcovid topics\n",
      "updating other broad topics in litcovid\n",
      "updating clinical trials annotations\n",
      "fetching subtopics from litcovid via keyword-mapping\n",
      "fetching all available subtopic data\n",
      "Wall time: 1h 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Update all topics\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from src.common import *\n",
    "\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "CLINDATAPATH = os.path.join(SUBDATAPATH ,'ct_topics/')\n",
    "\n",
    "print('fetching litcovid topics')\n",
    "from src.fetch_litcovid_topics import *\n",
    "get_litcovid_topics(DATAPATH)\n",
    "\n",
    "print('updating other broad topics in litcovid')\n",
    "from src.fetch_offtopics import *\n",
    "get_other_topics(DATAPATH,RESULTSPATH)\n",
    "\n",
    "print('updating clinical trials annotations')\n",
    "from src.fetch_clinical_trials import *\n",
    "update_clin_cats(DATAPATH,CLINDATAPATH)\n",
    "\n",
    "print('fetching subtopics from litcovid via keyword-mapping')      \n",
    "from src.fetch_litsubtopics import *\n",
    "from src.fetch_litcovid_topics import *\n",
    "get_sub_topics(DATAPATH,RESULTSPATH)\n",
    "map_keywords(DATAPATH)\n",
    "\n",
    "print('fetching all available subtopic data')\n",
    "from src.fetch_subtopics import *\n",
    "subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "\n",
    "### run time:1h 10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SUBDATAPATH,'subtopics_only.pickle'),'rb') as save_file:\n",
    "    subtopics_only = pickle.load(save_file)\n",
    "print(subtopics_only.groupby('topicCategory').size().reset_index(name='counts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### update models for all subtopic \n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.train_classifier import *\n",
    "from src.fetch_subtopics import *\n",
    "from src.common import topic_dict\n",
    "\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "SUBMODELPATH = os.path.join(MODELPATH,'subtopics/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "\n",
    "with open(os.path.join(SUBDATAPATH,'subtopics_only.pickle'),'rb') as save_file:\n",
    "    subtopics_only = pickle.load(save_file)\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "generate_models(SUBMODELPATH,subtopics_only,classifiers,\"all\",False)\n",
    "\n",
    "## This took 9hrs, 10 min\n",
    "## Adding a limitation on max training size (30000) actually slowed down the script, so it was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## update models\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.train_classifier import *\n",
    "from src.fetch_subtopics import *\n",
    "from src.common import topic_dict\n",
    "\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "SUBMODELPATH = os.path.join(MODELPATH,'subtopics/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "\n",
    "models_to_update = 'i'\n",
    "while models_to_update not in ['b','a','s','c']:\n",
    "    models_to_update = input(\"Which models need to be updated? (b: broad topics, c: child/sub-topics, a: all topics, s: single topic\")\n",
    "\n",
    "if models_to_update == 'a':\n",
    "    topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "    topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "    generate_models(MODELPATH,topicsdf,classifiers) \n",
    "    subtopics_only = load_subtopics_data(SUBDATAPATH,RESULTSPATH,topic_dict)\n",
    "    generate_models(SUBMODELPATH,subtopics_only,classifiers,\"all\",False)\n",
    "elif models_to_update == 'b':\n",
    "    topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "    topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "    generate_models(MODELPATH,topicsdf,classifiers)\n",
    "elif models_to_update == 'c':\n",
    "    subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "    generate_models(SUBMODELPATH,subtopics_only,classifiers,\"all\",False)\n",
    "elif models_to_update == 's':\n",
    "    topic_to_check = input(\"enter the topic Category: \")\n",
    "    if topic_to_check in topic_dict['broadtopics']:\n",
    "        topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "        topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "        generate_models(MODELPATH,topicsdf,classifiers,topic_to_check)\n",
    "    else:\n",
    "        subtopics_only = load_subtopics_data(DATAPATH,RESULTSPATH,topic_dict)\n",
    "        generate_models(SUBMODELPATH,subtopics_only,classifiers,topic_to_check,False)        \n",
    "\n",
    "#### Subtopics update run time: 2hrs 52 min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### classify clinical trials\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "from src.common import topic_dict\n",
    "\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "classify_clins(DATAPATH,MODELPATH,PREDICTPATH,classifiers,topic_dict)\n",
    "\n",
    "#### run time: 4 min, 17 sec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### classify publications\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "\n",
    "\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "subtopicsfile = os.path.join(DATAPATH,'subtopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopicsdf = read_csv(subtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "topiclist = topicsdf['topicCategory'].unique().tolist() \n",
    "allsubslist = subtopicsdf['topicCategory'].unique().tolist()\n",
    "subtopiclist = [x for x in allsubslist if x not in topiclist]\n",
    "\n",
    "new_pubs_only,new_topic_ids = check_for_new(RESULTSPATH,topicsdf,\"nonlitcovid\")\n",
    "all_new_ids = list(set(new_pubs_only).union(set(new_topic_ids)))\n",
    "newonly = False\n",
    "alldf = batch_fetch_meta(all_new_ids)\n",
    "alldata = merge_texts(alldf)    \n",
    "\n",
    "classifiers = load_classifiers(\"best\")\n",
    "classifierlist = classifiers.keys()\n",
    "PUBPREDICTPATH = os.path.join(PREDICTPATH,'pubpredict/')\n",
    "SUBMODELPATH = os.path.join(MODELPATH,'subtopics/')\n",
    "\n",
    "if newonly == True:\n",
    "    predict_class(MODELPATH,PUBPREDICTPATH,topiclist,classifierlist,alldata,True)\n",
    "    predict_class(MODELPATH,PUBPREDICTPATH,topiclist,classifierlist,alldata,True)\n",
    "else:\n",
    "    predict_class(SUBMODELPATH,PUBPREDICTPATH,subtopiclist,classifierlist,alldata,False)\n",
    "    predict_class(MODELPATH,PUBPREDICTPATH,topiclist,classifierlist,alldata,False)\n",
    "\n",
    "\n",
    "#### runtime: 1 hr 28 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run tests\n",
    "RESULTPATH = 'results/'\n",
    "testresultsdf = run_test(RESULTPATH,topicsdf,classifierset_type='best',export_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### load annotations\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "from datetime import datetime\n",
    "\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "#subtopicsfile = os.path.join(DATAPATH,'subtopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "#subtopicsdf = read_csv(subtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopic_results = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf,subtopic_results),ignore_index=True)\n",
    "topicsdf.drop_duplicates(keep='first',inplace=True)\n",
    "topicsdf.reset_index(drop=True)\n",
    "\n",
    "print('topicsdf: Molecular Epi: ',len(topicsdf.loc[topicsdf['topicCategory']=='Molecular Epidemiology']))\n",
    "print('topicsdf: Molecular Epi PMIDs: ',len(topicsdf.loc[((topicsdf['topicCategory']=='Molecular Epidemiology')&\n",
    "                                               (topicsdf['_id'].str.contains('pmid',regex=False)))]))\n",
    "\n",
    "topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "classifiers = load_classifiers('best')\n",
    "newonly=False\n",
    "\n",
    "#classify_clins(DATAPATH,MODELPATH,PREDICTPATH,classifiers,topic_dict)\n",
    "from src.common import topic_dict\n",
    "classifierlist = classifiers.keys()\n",
    "CLINPREDICTPATH = os.path.join(PREDICTPATH,'clinpredict/')\n",
    "PUBPREDICTPATH = os.path.join(PREDICTPATH,'pubpredict/')\n",
    "classify_clins(DATAPATH,MODELPATH,PREDICTPATH,classifiers,topic_dict)\n",
    "clin_total_agree = merge_predictions(CLINPREDICTPATH,topic_dict,classifierlist,agreetype='perfect')\n",
    "if newonly==True:\n",
    "    new_pubs_only,new_topic_ids = check_for_new(RESULTSPATH,topicsdf,\"nonlitcovid\")\n",
    "    all_new_ids = list(set(new_pubs_only).union(set(new_topic_ids)))\n",
    "    classify_pubs(MODELPATH,PUBPREDICTPATH,new_pubs_only,topic_dict,classifiers)\n",
    "    total_agree = merge_predictions(PUBPREDICTPATH,topic_dict,classifierlist,'perfect')\n",
    "    new_total_agree = total_agree.loc[total_agree['_id'].isin(new_pubs_only)].copy()\n",
    "    new_topics_df = topicsdf.loc[topicsdf['_id'].isin(new_topic_ids)].copy()\n",
    "    totalnewresults = pd.concat((new_total_agree,new_topics_df,clin_total_agree),ignore_index=True)\n",
    "    allnewresults = include_clin(totalnewresults)\n",
    "    allnewresults['topicCategory'] = allnewresults['topicCategory'].str.replace('-','/')\n",
    "    allnewresults.dropna(axis=0,inplace=True)\n",
    "    allnewresults.reset_index(drop=True)\n",
    "    cleanresults = clean_results(allnewresults)\n",
    "    cleanresults.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),mode='a',sep='\\t',header=True)\n",
    "else:\n",
    "    all_ids = get_pub_ids(sourceset=\"nonlitcovid\")\n",
    "    classify_pubs(MODELPATH,PUBPREDICTPATH,all_ids,topic_dict,classifiers,False)\n",
    "    total_agree = merge_predictions(PUBPREDICTPATH,topic_dict,classifierlist,'perfect')\n",
    "    totalresults = pd.concat((total_agree,topicsdf,clin_total_agree),ignore_index=True)\n",
    "    print('total results: ',len(totalresults))\n",
    "    allresults = include_clin(totalresults)\n",
    "    print('allresults: ',len(allresults))\n",
    "    allresults['topicCategory'] = allresults['topicCategory'].str.replace('-','/')\n",
    "    allresults.dropna(axis=0,inplace=True)\n",
    "    print('allresults less na: ',len(allresults))\n",
    "    allresults.reset_index(drop=True)\n",
    "    print('allresults with new index: ',len(allresults))\n",
    "    cleanresults = clean_results(allresults) \n",
    "    print('clean results: ',len(cleanresults))\n",
    "    cleanresults.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),mode='w',sep='\\t',header=True)\n",
    "updated_results = read_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "updated_results.drop_duplicates(subset='_id',keep='first',inplace=True)\n",
    "updated_results.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),sep='\\t',header=True)\n",
    "updated_results.to_json(os.path.join(RESULTSPATH,'topicCats.json'), orient='records')\n",
    "\n",
    "####time: 3hrs 14 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inspect the results\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopicsdf = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "subtopicsdf.dropna(axis=0,inplace=True)\n",
    "\n",
    "litsub = subtopicsdf.loc[subtopicsdf['_id'].str.contains('pmid')]\n",
    "litcovidtopics = pd.concat((littopicsdf,offtopicsdf,litsub),ignore_index=True)\n",
    "litcovidtopics.drop_duplicates(keep='first',inplace=True)\n",
    "litcovidtopics.dropna(axis=0,inplace=True)\n",
    "littopicfreq = litcovidtopics.groupby('topicCategory').size().reset_index(name='litcounts')\n",
    "\n",
    "updated_results = read_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),delimiter='\\t',header=0,index_col=0,converters={\"topicCategory\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "check_it = updated_results.explode('topicCategory')\n",
    "frequency = check_it.groupby('topicCategory').size().reset_index(name='allcounts')\n",
    "\n",
    "from src.fetch_subtopics import load_citsci_data\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "curate_df = load_citsci_data(SUBDATAPATH)\n",
    "curate_freq = curate_df.groupby('topicCategory').size().reset_index(name='citsci_counts')\n",
    "curate_freq['topicCategory'] = curate_freq['topicCategory'].str.replace(' / ','/')\n",
    "\n",
    "rawclinical = check_it.loc[check_it['_id'].str.contains('NCT|DKRS|DRKS|ACTRN|ChiCTR|IRCT')].copy()\n",
    "clinicalfreq = clinical.groupby('topicCategory').size().reset_index(name='clinical_counts')\n",
    "\n",
    "rawpreprint = check_it.loc[~(check_it['_id'].str.contains('NCT|DKRS|DRKS|ACTRN|ChiCTR|IRCT|pmid|zenodo|pdb|figshare'))].copy()\n",
    "preprintfreq = rawpreprint.groupby('topicCategory').size().reset_index(name='preprint_count')\n",
    "\n",
    "basic_info = frequency.merge(littopicfreq.merge(curate_freq,on='topicCategory',how='outer'),on='topicCategory',how='outer').fillna(0)\n",
    "freq_info = basic_info.merge(clinicalfreq.merge(preprintfreq,on='topicCategory',how='outer'),on='topicCategory',how='outer').fillna(0)\n",
    "\n",
    "freq_info.to_csv(os.path.join(RESULTSPATH,'topic_frequencies.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## refresh annotations\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "#### MAIN\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopic_results = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf,subtopic_results),ignore_index=True)\n",
    "topicsdf.drop_duplicates(keep='first',inplace=True)\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "load_annotations(DATAPATH,MODELPATH,PREDICTPATH,RESULTSPATH,topicsdf,classifiers,False)\n",
    "\n",
    "#### run time: 8 hr 46 min\n",
    "#### After efficiency changes implemented, run time was: 2 hr 13 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## update annotations\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "#### MAIN\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "subtopic_results = read_csv(os.path.join(RESULTSPATH,'subtopicCats.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf,subtopic_results),ignore_index=True)\n",
    "topicsdf.drop_duplicates(keep='first',inplace=True)\n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "load_annotations(DATAPATH,MODELPATH,PREDICTPATH,RESULTSPATH,topicsdf,classifiers,True)\n",
    "\n",
    "#### run time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speed up map_keywords function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.fetch_subtopics import *\n",
    "from src.common import *\n",
    "from src.fetch_litsubtopics import *\n",
    "\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = ''\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "SUBMODELPATH = os.path.join(MODELPATH,'subtopics/')\n",
    "\n",
    "map_keywords(DATAPATH)\n",
    "\n",
    "SUBDATAPATH = os.path.join(DATAPATH,'subtopics/')\n",
    "with open(os.path.join(SUBDATAPATH,'subtopic_pmids_for_training.pickle'),\"rb\") as dumpfile:\n",
    "    curated_pmids_df = pickle.load(dumpfile)\n",
    "\n",
    "print(curated_pmids_df.loc[curated_pmids_df['topicCategory']=='Repurposing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
